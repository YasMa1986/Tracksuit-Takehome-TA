{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be8eb4f7",
   "metadata": {},
   "source": [
    "## Baseline (Naive) cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "113a9017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   category_id                category_name  incidence_rate  \\\n",
      "0            1     Fertility or IVF service        0.095621   \n",
      "1            2  Big and Tall Men's Clothing        0.131231   \n",
      "2            4       Self Tan (Female Only)        0.191096   \n",
      "3            5                 Baby Feeding        0.198451   \n",
      "4            6                Baby products        0.188133   \n",
      "\n",
      "   category_length_seconds  \n",
      "0               164.504580  \n",
      "1                69.826299  \n",
      "2               115.928005  \n",
      "3               166.231168  \n",
      "4                60.252290  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77 entries, 0 to 76\n",
      "Data columns (total 4 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   category_id              77 non-null     int64  \n",
      " 1   category_name            77 non-null     object \n",
      " 2   incidence_rate           77 non-null     float64\n",
      " 3   category_length_seconds  77 non-null     float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 2.5+ KB\n",
      "None\n",
      "       category_id  incidence_rate  category_length_seconds\n",
      "count    77.000000       77.000000                77.000000\n",
      "mean     39.974026        0.469328               108.804426\n",
      "std      22.416497        0.202952                40.639092\n",
      "min       1.000000        0.095621                32.008550\n",
      "25%      21.000000        0.308978                79.859201\n",
      "50%      40.000000        0.425092               104.654886\n",
      "75%      59.000000        0.617270               145.476213\n",
      "max      78.000000        0.885174               178.785914\n",
      "                 category_name  incidence_rate  required_respondents_if_alone\n",
      "0     Fertility or IVF service        0.095621                    2091.594202\n",
      "1  Big and Tall Men's Clothing        0.131231                    1524.024641\n",
      "2       Self Tan (Female Only)        0.191096                    1046.594982\n",
      "3                 Baby Feeding        0.198451                    1007.806691\n",
      "4                Baby products        0.188133                    1063.079777\n",
      "Naive total respondents: 40879.139181607185\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load data\n",
    "# -----------------------------\n",
    "# Read the fake category data (update the path if needed)\n",
    "df = pd.read_csv(r\"D:\\General Drive\\Tracksuit-Takehome-TA\\Tracksuit-Takehome-TA\\fake_category_data.csv\")\n",
    "\n",
    "# Quick sanity checks: preview rows, data types, and summary statistics\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Baseline (Naive) cost\n",
    "# -----------------------------\n",
    "# If we ran each category alone, to get ~200 qualified respondents:\n",
    "# expected required respondents = 200 / incidence_rate\n",
    "df[\"required_respondents_if_alone\"] = 200 / df[\"incidence_rate\"]\n",
    "\n",
    "# View the computed requirement per category\n",
    "print(df[[\"category_name\", \"incidence_rate\", \"required_respondents_if_alone\"]].head())\n",
    "\n",
    "# Naive total cost = sum of required respondents across categories\n",
    "total_cost_naive = df[\"required_respondents_if_alone\"].sum()\n",
    "print(\"Naive total respondents:\", total_cost_naive)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b59ccc",
   "metadata": {},
   "source": [
    "## Greedy packing optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea9fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3) Greedy Packing (Bin Packing by time constraint)\n",
    "# -----------------------------\n",
    "# Sort categories so that the \"hardest/most expensive\" categories (low incidence) are allocated first\n",
    "df_sorted = df.sort_values(\"required_respondents_if_alone\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "MAX_TIME = 480  # 8 minutes in seconds\n",
    "survey_groups = []  # each group is a \"survey version\" (list of categories)\n",
    "\n",
    "# Greedy first-fit packing:\n",
    "# Place each category into the first group where it fits under MAX_TIME.\n",
    "# If no group fits, create a new group.\n",
    "for _, row in df_sorted.iterrows():\n",
    "    placed = False\n",
    "\n",
    "    for group in survey_groups:\n",
    "        total_time = sum(cat[\"category_length_seconds\"] for cat in group)\n",
    "\n",
    "        # If adding this category keeps total time <= MAX_TIME, put it in this group\n",
    "        if total_time + row[\"category_length_seconds\"] <= MAX_TIME:\n",
    "            group.append(row)\n",
    "            placed = True\n",
    "            break\n",
    "\n",
    "    # If it didn't fit anywhere, start a new survey group\n",
    "    if not placed:\n",
    "        survey_groups.append([row])\n",
    "\n",
    "# Print number of survey versions created (after the loop, not inside it)\n",
    "print(\"Number of survey groups using greedy first-fit packing:\", len(survey_groups))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65002185",
   "metadata": {},
   "source": [
    "## Estimate required respondents per group and build a summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a59e768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated total respondents (no buffer): 11069.24477046791\n",
      "Survey groups summary saved.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4) Estimate required respondents per group (deterministic)\n",
    "# -----------------------------\n",
    "# Idea:\n",
    "# - Each respondent completes exactly ONE survey group.\n",
    "# - Within a group, respondents may qualify for multiple categories.\n",
    "# - To hit ~200 qualified respondents for every category (on average),\n",
    "#   we need at least enough respondents to satisfy the \"hardest\" category in that group.\n",
    "#   (\"Hardest\" = the one that needs the most respondents if run alone, i.e., 200 / incidence.)\n",
    "# - So: required respondents for a group ≈ max(required_respondents_if_alone) across its categories.\n",
    "\n",
    "max_required_list = []\n",
    "\n",
    "for group in survey_groups:\n",
    "    # Find the maximum required respondents among categories inside this group\n",
    "    # (this determines the group-level respondent requirement)\n",
    "    max_required = max(cat[\"required_respondents_if_alone\"] for cat in group)\n",
    "    max_required_list.append(max_required)\n",
    "\n",
    "# Total estimated respondents across all groups\n",
    "# (since groups are run separately and each respondent is assigned to one group)\n",
    "total_required = sum(max_required_list)\n",
    "\n",
    "print(\"Estimated total respondents (no buffer):\", total_required)\n",
    "\n",
    "# -----------------------------\n",
    "# Build a summary table for each group\n",
    "# -----------------------------\n",
    "# We record:\n",
    "# - group_id: sequential id starting from 1\n",
    "# - num_categories: how many categories are in the group\n",
    "# - total_time_seconds: total interview time if someone answers all categories in that group\n",
    "# - max_required_no_buffer: deterministic respondent estimate for the group (no safety buffer)\n",
    "groups_summary = []\n",
    "\n",
    "for i, group in enumerate(survey_groups, start=1):\n",
    "    groups_summary.append({\n",
    "        \"group_id\": i,\n",
    "        \"num_categories\": len(group),\n",
    "        \"total_time_seconds\": sum(cat[\"category_length_seconds\"] for cat in group),\n",
    "        \"max_required_no_buffer\": max(cat[\"required_respondents_if_alone\"] for cat in group)\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and save for reporting / inspection\n",
    "groups_df = pd.DataFrame(groups_summary)\n",
    "groups_df.to_csv(\"survey_groups_summary.csv\", index=False)\n",
    "\n",
    "print(\"Survey groups summary saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb9e330",
   "metadata": {},
   "source": [
    "## Monte carlo simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e7ffcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to validation_results.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def simulate_group(group_df, N, target=200, n_sims=500, seed=42):\n",
    "    \"\"\"\n",
    "    Monte Carlo simulation to validate whether a survey group\n",
    "    achieves at least `target` qualified respondents per category.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    group_df : DataFrame\n",
    "        Contains categories in this survey version with their incidence_rate.\n",
    "    N : int\n",
    "        Number of respondents assigned to this survey version.\n",
    "    target : int\n",
    "        Required number of qualified respondents per category (default=200).\n",
    "    n_sims : int\n",
    "        Number of Monte Carlo simulation runs.\n",
    "    seed : int\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Summary statistics including success rate and distribution of minimum qualified counts.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Initialize random generator (ensures reproducible results)\n",
    "    # ----------------------------------------------------------\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Extract incidence probabilities for categories\n",
    "    # ----------------------------------------------------------\n",
    "    # ps = array of probabilities (one per category)\n",
    "    ps = group_df[\"incidence_rate\"].to_numpy()\n",
    "    k = len(ps)  # number of categories in this group\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Storage variables for simulation tracking\n",
    "    # ----------------------------------------------------------\n",
    "    success = 0       # counts how many simulations succeed (all categories ≥ target)\n",
    "    min_quals = []    # stores worst-category qualification count per simulation\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Monte Carlo simulation loop\n",
    "    # ----------------------------------------------------------\n",
    "    for _ in range(n_sims):\n",
    "\n",
    "        # Simulate number of qualified respondents per category\n",
    "        # For each category:\n",
    "        #   q_i ~ Binomial(N respondents, probability p_i)\n",
    "        # This assumes independence between respondents\n",
    "        q = rng.binomial(N, ps)\n",
    "\n",
    "        # Store minimum qualified count (worst performing category)\n",
    "        min_quals.append(q.min())\n",
    "\n",
    "        # Check if ALL categories reached required target\n",
    "        if (q >= target).all():\n",
    "            success += 1\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Return validation statistics\n",
    "    # ----------------------------------------------------------\n",
    "    return {\n",
    "        \"N\": N,  # respondents assigned to this group\n",
    "        \"k_categories\": k,  # number of categories in group\n",
    "        \"success_rate\": success / n_sims,  # probability all categories hit target\n",
    "        \"min_qualified_mean\": float(np.mean(min_quals)),  # average worst-case category\n",
    "        \"min_qualified_p05\": float(np.quantile(min_quals, 0.05)),  # 5th percentile (risk measure)\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# Run validation for all survey groups\n",
    "# ==========================================================\n",
    "\n",
    "results = []\n",
    "\n",
    "for group in survey_groups:\n",
    "\n",
    "    # Convert group (list of dictionaries) into DataFrame\n",
    "    group_df = pd.DataFrame(group)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Deterministic baseline estimate:\n",
    "    # Hardest category determines required respondents\n",
    "    # (i.e., the one needing the most respondents if run alone)\n",
    "    # ----------------------------------------------------------\n",
    "    max_required = max(cat[\"required_respondents_if_alone\"] for cat in group)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Apply safety buffer (e.g., +20%)\n",
    "    # This reduces probability of falling below 200 due to randomness\n",
    "    # ----------------------------------------------------------\n",
    "    N = int(np.ceil(max_required * 1.20))\n",
    "\n",
    "    # Run Monte Carlo validation\n",
    "    res = simulate_group(group_df, N)\n",
    "\n",
    "    results.append(res)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Convert results to DataFrame for reporting\n",
    "# ----------------------------------------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results for documentation / report\n",
    "results_df.to_csv(\"validation_results.csv\", index=False)\n",
    "\n",
    "print(\"Results saved to validation_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
